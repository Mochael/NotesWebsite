<html>
<head>
<title>Main Website</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link href="index.css" rel="stylesheet">
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script><link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">
<script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>
<style>

body {
  margin: 0;
  font-family: Arial, Helvetica, sans-serif;
  color: white;
}

.topnav {
  background-color: none;
  position: fixed;
  top: 0;
  left: 0;
  z-index: 9999;
  width: 100%;
  height: 50px;
}

.topnav a {
  float: left;
  color: #f2f2f2;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 17px;
}

.topnav a:hover {
  background-color: #ddd;
  color: black;
}

.topnav a.active {
  background-color: #4CAF50;
  color: white;
}

.btn {
    padding: 14px 24px;
    border: 0 none;
    font-weight: 700;
    text-transform: none;
    outline: 0 none;
    background: none;
    color: #ffffff;
    font-size: 50px;
}
 
.btn:focus, .btn:active:focus, .btn.active:focus {
    outline: 0 none;
}
 
.btn:hover {
    background: none;
    color: #4CAF50;
}

a:link {
  color: white; 
  background-color: transparent; 
  text-decoration: none;
}

a:visited {
  color: white;
  background-color: transparent;
  text-decoration: none;
}

a:hover {
  color: lightgreen;
  background-color: transparent;
  text-decoration: none;
}

a:active {
  color: white;
  background-color: transparent;
  text-decoration: none;
}

#particles-js{
  position: absolute;
  width: 100%;
  height: 100%;
  z-index: -1;
  background-color: #2D2E2D;
  background-image: url('');
  background-size: cover;
  background-position: 50% 50%;
  background-repeat: no-repeat;
}
</style>
  </head>
  <body>
  
  <div class="topnav sticky-top">
    <a href="index.html">Home</a>
    <a href="notes.html">Notes</a>
    <a href="resume.pdf">Resume</a>
    <a class="active" href="projects.html">Projects</a>
  </div>

  <div id="particles-js" style="position:fixed;width:100%;z-index:-10;"></div>
<script src="particles.js"></script>
<script src="app.js"></script>
<script>
    AOS.init();
</script>
<div data-aos="fade-up" data-aos-duration="2000">
<div class="panel-group" id="accordion" style ="padding-top: 75px;">
    <div class="panel panel-default">
        <div class="panel-heading">
          <h4 class="panel-title">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapse10" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
              Song Year Prediction</a>
          </h4>
        </div>
        <div id="collapse10" class="panel-collapse collapse in">
          <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
            This was my final project for 10-701 Intro to Machine Learning (PhD). I worked with Tanishq Kancharla (a good friend of mine) to examine useful predictors for the year a song was released.
            We used the million song dataset and various machine learning models to measure how well we could predict the year a song was released. 
            Our main goal was to test if we could predict the release year more accurately using the song lyrics rather than using the complex and esoteric musical information provided by the million song dataset.
          </div>
        </div>
    </div>

    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse1" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
            Modeling the Quantum Many-Body Problem</a>
        </h4>
      </div>
      <div id="collapse1" class="panel-collapse collapse in">
        <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
          I worked with Tanishq Kancharla, Anoop Bhat, and Evann Wu with Andrew Smith advising us to create a restricted Boltzmann machine that would simulate the evolution of quantum mechanical system. 
          Given a Hamiltonian operator, the restricted Boltzmann machine used gradient descent to find the lowest energy superposition for the input system.
        </div>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse2" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
            Carnegie Mellon Racing System Lead</a>
        </h4>
      </div>
      <div id="collapse2" class="panel-collapse collapse">
        <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
          I led the design of the car pedals for the Carnegie Mellon Racing Team's 2019 car. Every year the team builds a fully functional formula one electric race car that they race against other teams.
        </div>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse3" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
            Website Prototyping System</a>
        </h4>
      </div>
      <div id="collapse3" class="panel-collapse collapse">
        <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
          I worked with Bradley Zhou, Candia Gu, and Aditi Hebbar, to created an automatic html file from a user drawn image. The application works by having users draw the layout of a website on a sheet of paper. The user’s phone is positioned on top of the acrylic mount where the phone camera records each iteration of their sketch in real time, which is then translated directly to a live website, displayed on the user’s computer.
          Using a mobile app created using React Native, our smartphone camera intermittently takes photos and sends them directly to a Flask API hosted on Heroku. This API then takes the image of the paper website layout and processes it and isolates each of its components using OpenCV. We then differentiate between each type of component, such as images and text, and reformat them to HTML. Finally, the rendered HTML is displayed live on the same website
        </div>
      </div>
    </div>
    <div class="panel panel-default">
        <div class="panel-heading">
          <h4 class="panel-title">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapse4" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
              Automated Logo Generator</a>
          </h4>
        </div>
        <div id="collapse4" class="panel-collapse collapse">
          <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
            I worked with Evann Wu, Ka Chun CHeung, and Tanishq Kancharla to build an app that would take in user input and automatically output a logo based on their descriptions. 
            We used Adobe Illustrator's Javascript API to perform the image manipulation and Microsoft Azure to identify the main object as well as associated details from the image that they scan in.
          </div>
        </div>
      </div>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse5" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
            Professor Doppleganger</a>
        </h4>
      </div>
      <div id="collapse5" class="panel-collapse collapse">
        <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
          I worked with Evann Wu and Tanishq Kancharla to create a website that would take in an image url and match it a CMU professor in CMU's database who looked the most similar. 
          We used the Microsoft Azure API to extract traits from the input image and then match it image with the most similar looking professor.
        </div>
      </div>
    </div>
    <div class="panel panel-default">
        <div class="panel-heading">
          <h4 class="panel-title">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapse6" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
            Intellichess</a>
          </h4>
        </div>
        <div id="collapse6" class="panel-collapse collapse">
          <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
            This was the final project for my introductory programming class at CMU 15-112. I had no real programming experience prior to taking this class, and I very much enjoyed working on this project, which allowed me to practice all that I had learned as well as learn new skills.
            This project also introduced me to machine learning, and it was one of the major reasons I switched majors from business to statistics and machine learning. For this project, I developed a fully functioning chess game using python. The game had three main modes: training, competitive, and multiplayer.
            In the training mode players could practice playing against themselves to tray out different moves. In the competitive mode I developed a chess AI that used minimax search algorithm to find the optimal moves with a neural network that scored each board that would be encountered with the minimax search. 
            I made the neural network entirely by myself, so it was not very skilled at playing chess. I trained the neural network based on the great chess engine Stockfish's board evaluations, using a database of grandmaster games in .pgn formatting. I used sockets to implement multiplayer in the game.
          </div>
        </div>
      </div>
      <div class="panel panel-default">
        <div class="panel-heading">
          <h4 class="panel-title">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapse7" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
            GunAR</a>
          </h4>
        </div>
        <div id="collapse7" class="panel-collapse collapse">
          <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
            I worked with Alex Li, Evann Wu, and Tanishq Kancharla to develop GunAR for CMU's Build18 competition. I really liked this project because it had so many cool elements. 
            The goal of the project was to develop a laser tag game that used computer vision to identify when you had been shot. The user would mount their phone on top of our toy gun, and when the trigger was pressed, a bluetooth signal would be sent to the user's phone that would be running our application. 
            If that person's enemy was in their crosshairs on the phone, then it would register as a hit just based off of the position of the target in the phones camera. 
            We had a competitive mode where players could play against each other and a single playeer mode where virtual reality targets were spawned for the user to shoot at. 
            Unfortunately we ran out of time to complete the project and put together all of the project's different pieces, but I though that the experience was quite cool, and it led to me taking 18-100 Introduction to Electrical and Computer Engineering.
          </div>
        </div>
      </div>
      <div class="panel panel-default">
        <div class="panel-heading">
          <h4 class="panel-title">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapse8" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
              Automated Tool Path Planning</a>
          </h4>
        </div>
        <div id="collapse8" class="panel-collapse collapse">
          <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
            I worked with Trevor Daino and Arpad Voros with Joshua Tarbutton as our advisor at UNCC to design a desktop CNC milling machine to be used with automated tool path planning software. 
            We designed a working machine that user polar coordinates, so we could reduce some costs from the AC servo motors, however the machine was never built.
          </div>
        </div>
      </div>
      <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse9" style="font-weight: bold; margin-left: 25px; margin-right: 25px; font-size: 50px;">
            Muon Scattering Tomography</a>
        </h4>
      </div>
      <div id="collapse9" class="panel-collapse collapse in">
        <div class="panel-body" style="margin-left: 25px; margin-right: 25px;">
          I worked with Trevor Daino and Arpad Voros to design a new way to detect the trajectory high energy muon particles, for the purposes of muon tomography. 
          Our idea was to have 4 layers of plastic scintillators each paired with a silicon photomultiplier array to triangulate the muon's position at each layer and then use the change in positions from layer to layer to find the muon's trajectory. 
          We would put an object in the middle of the device (between two top layers and two bottom layers) so that we could measure the deflection of the muon after penetrating through the object. 
          In order to test our theory we spend over a thousand dollars of our own saved money to build a protoype model. We tested our protoype using UV light (our prototype was no where near precise enough to pinpoint muons since we built it in a garage as amateurs), 
          and we also built a simulation of how our device in java and matlab. We presented our findings at the Intel International Science and Engineering Fair where we placed 3rd in the Physics and Astronomy category.
        </div>
      </div>
    </div>
  </div>
</div>

</body>
</html>